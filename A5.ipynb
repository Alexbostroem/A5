{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Warmup\n",
    "As a warmup, write code to collect statistics about word frequencies in the two languages. Print the 10 most frequent words in each language.\n",
    "\n",
    "If you're working with Python, using a CounterLinks to an external site. is probably the easiest solution.\n",
    "\n",
    "Let's assume that we pick a word completely randomly from the European parliament proceedings. According to your estimate, what is the probability that it is speaker? What is the probability that it is zebra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sent(file_path):\n",
    "    sent = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            sentences = re.split(r'\\s', line.strip())\n",
    "            for sentance in sentences:\n",
    "                if sentance.strip():\n",
    "                    sent.append(sentance.strip())\n",
    "\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_swe = \"datasets/europarl-v7.sv-en.lc.sv\"\n",
    "swe_sentance = extract_sent(file_path_swe)\n",
    "file_path_eng = \"datasets/europarl-v7.sv-en.lc.en\"\n",
    "eng_sentance = extract_sent(file_path_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".: 9648\n",
      "att: 9181\n",
      ",: 8876\n",
      "och: 7038\n",
      "i: 5949\n",
      "det: 5687\n",
      "som: 5028\n",
      "för: 4959\n",
      "av: 4013\n",
      "är: 3840\n"
     ]
    }
   ],
   "source": [
    "counter_swe = Counter(swe_sentance)\n",
    "most_common_swe = counter_swe.most_common(10)\n",
    "for word, count in most_common_swe:\n",
    "   print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 19322\n",
      ",: 13514\n",
      ".: 9774\n",
      "of: 9312\n",
      "to: 8801\n",
      "and: 6946\n",
      "in: 6090\n",
      "is: 4400\n",
      "that: 4357\n",
      "a: 4269\n"
     ]
    }
   ],
   "source": [
    "counter_eng = Counter(eng_sentance)\n",
    "most_common_eng = counter_eng.most_common(10)\n",
    "for word, count in most_common_eng:\n",
    "   print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of picking 'speaker' randomly: 0.0009008197459688316\n",
      "Probability of picking 'zebra' randomly: 0.0\n",
      "Probability of picking 'the' randomly: 1.7405639131609765\n"
     ]
    }
   ],
   "source": [
    "total_words_eng = len(counter_eng)\n",
    "speaker_counts = counter_eng['speaker']\n",
    "zebra_counts = counter_eng['zebra']\n",
    "the_counts = counter_eng['the']\n",
    "\n",
    "prob_speaker = speaker_counts/total_words_eng\n",
    "prob_zebra = zebra_counts/total_words_eng\n",
    "prob_the= the_counts / total_words_eng \n",
    "\n",
    "print(\"Probability of picking 'speaker' randomly:\", prob_speaker)\n",
    "print(\"Probability of picking 'zebra' randomly:\", prob_zebra)\n",
    "print(\"Probability of picking 'the' randomly:\", prob_the)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Language modeling\n",
    "We will now define a language model that lets us compute probabilities for individual English sentences.\n",
    "\n",
    "Implement a bigram language model as described in the lecture, and use it to compute the probability of a short sentence.\n",
    "What happens if you try to compute the probability of a sentence that contains a word that did not appear in the training texts? And what happens if your sentence is very long (e.g. 100 words or more)? Optionally, change your code so that it can handle these challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation_model(data, sequence):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
