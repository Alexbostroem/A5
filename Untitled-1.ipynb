{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from collections import Counter, defaultdict  \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Top 10 translations for the English word 'european':\n",
      "personer: 0.03703703703703704\n",
      "nyligen: 0.03703703703703704\n",
      "mördades: 0.03703703703703704\n",
      "kumar: 0.03703703703703704\n",
      "ponnambalam: 0.03703703703703704\n",
      "besökte: 0.03703703703703704\n",
      "bara: 0.03703703703703704\n",
      "månader: 0.03703703703703704\n",
      "föreslår: 0.03448275862068965\n",
      "röstar: 0.03448275862068965\n",
      "\n",
      "Iteration 2:\n",
      "Top 10 translations for the English word 'european':\n",
      "dess: 0.04969107246932571\n",
      "europaparlamentet: 0.04447611835136042\n",
      "uttalande: 0.04119467091259389\n",
      "samt: 0.04076888134095893\n",
      "personer: 0.03958641739566613\n",
      "nyligen: 0.03958641739566613\n",
      "mördades: 0.03958641739566613\n",
      "kumar: 0.03958641739566613\n",
      "ponnambalam: 0.03958641739566613\n",
      "besökte: 0.03958641739566613\n",
      "\n",
      "Iteration 3:\n",
      "Top 10 translations for the English word 'european':\n",
      "dess: 0.08513355581513131\n",
      "europaparlamentet: 0.07796174800151279\n",
      "europeiska: 0.0775092581862694\n",
      "samt: 0.0773235225511381\n",
      "själv: 0.055163383258520896\n",
      "uttalande: 0.04930062672755437\n",
      "personer: 0.04123285974870843\n",
      "nyligen: 0.04123285974870843\n",
      "mördades: 0.04123285974870843\n",
      "kumar: 0.04123285974870843\n",
      "\n",
      "Iteration 4:\n",
      "Top 10 translations for the English word 'european':\n",
      "europeiska: 0.13946078132851447\n",
      "samt: 0.13018348035399507\n",
      "dess: 0.13003388024936563\n",
      "europaparlamentet: 0.11754589537609429\n",
      "själv: 0.08399369152094005\n",
      "uttalande: 0.05376648196744524\n",
      "texas: 0.052404394389593476\n",
      "ämbete: 0.051133111268685694\n",
      "år: 0.044489571571181136\n",
      "personer: 0.04248871263315199\n",
      "\n",
      "Iteration 5:\n",
      "Top 10 translations for the English word 'european':\n",
      "europeiska: 0.2113164665716514\n",
      "samt: 0.18996950986161631\n",
      "dess: 0.17577074063766923\n",
      "europaparlamentet: 0.15369465581250075\n",
      "själv: 0.11793016288967192\n",
      "texas: 0.06159793151449633\n",
      "ämbete: 0.05794142540544358\n",
      "uttalande: 0.05381397453424517\n",
      "år: 0.05379793112429071\n",
      "gruppen: 0.04380401241719091\n",
      "\n",
      "Iteration 6:\n",
      "Top 10 translations for the English word 'european':\n",
      "europeiska: 0.2798388064393053\n",
      "samt: 0.24487841275495847\n",
      "dess: 0.21612997462375447\n",
      "europaparlamentet: 0.1819523512804213\n",
      "själv: 0.15293778499714322\n",
      "texas: 0.06679155279104895\n",
      "år: 0.0603916767628104\n",
      "ämbete: 0.058139938101755224\n",
      "uttalande: 0.050621664702126694\n",
      "personer: 0.04367787953283956\n",
      "\n",
      "Iteration 7:\n",
      "Top 10 translations for the English word 'european':\n",
      "europeiska: 0.33804986714932356\n",
      "samt: 0.28781616912389446\n",
      "dess: 0.2489398726002095\n",
      "europaparlamentet: 0.20226239743051752\n",
      "själv: 0.18553546884730351\n",
      "texas: 0.06875829993687131\n",
      "år: 0.06471117021744609\n",
      "ämbete: 0.053266918464192695\n",
      "uttalande: 0.045844487130567046\n",
      "personer: 0.04396037369712024\n",
      "\n",
      "Iteration 8:\n",
      "Top 10 translations for the English word 'european':\n",
      "europeiska: 0.38456324175964324\n",
      "samt: 0.31719366089057344\n",
      "dess: 0.2743350018415256\n",
      "europaparlamentet: 0.21623196215523136\n",
      "själv: 0.2137743424082479\n",
      "texas: 0.06863703538538908\n",
      "år: 0.06754156421976103\n",
      "ämbete: 0.0458148980348503\n",
      "personer: 0.04414319493368004\n",
      "nyligen: 0.04414319493368004\n",
      "\n",
      "Iteration 9:\n",
      "Top 10 translations for the English word 'european':\n",
      "europeiska: 0.4206585312238717\n",
      "samt: 0.3347314340065752\n",
      "dess: 0.29336324001012687\n",
      "själv: 0.23726225167691778\n",
      "europaparlamentet: 0.22563533813092243\n",
      "år: 0.0695634340435838\n",
      "texas: 0.06737274837494577\n",
      "personer: 0.04426171151813541\n",
      "nyligen: 0.04426171151813541\n",
      "mördades: 0.04426171151813541\n",
      "\n",
      "Iteration 10:\n",
      "Top 10 translations for the English word 'european':\n",
      "europeiska: 0.448383844405831\n",
      "samt: 0.34340844518835645\n",
      "dess: 0.30731947740209803\n",
      "själv: 0.2565908051450074\n",
      "europaparlamentet: 0.23190096597852985\n",
      "år: 0.07123189685685478\n",
      "texas: 0.06558985044281582\n",
      "personer: 0.0443403183616112\n",
      "nyligen: 0.0443403183616112\n",
      "mördades: 0.0443403183616112\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 128\u001b[0m\n\u001b[0;32m    125\u001b[0m bigram_lm \u001b[38;5;241m=\u001b[39m BigramLanguageModel(english_corpus)\n\u001b[0;32m    127\u001b[0m swedish_sentence \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjag\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mber\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 128\u001b[0m best_translation, best_score \u001b[38;5;241m=\u001b[39m \u001b[43margmax_translation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mibm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbigram_lm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswedish_sentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSwedish Sentence:\u001b[39m\u001b[38;5;124m\"\u001b[39m, swedish_sentence)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest English Translation:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_translation)\n",
      "Cell \u001b[1;32mIn[4], line 89\u001b[0m, in \u001b[0;36margmax_translation\u001b[1;34m(ibm_model, language_model, swedish_sentence)\u001b[0m\n\u001b[0;32m     87\u001b[0m best_translation \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     88\u001b[0m best_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 89\u001b[0m translation \u001b[38;5;241m=\u001b[39m \u001b[43mibm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mswedish_sentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m score \u001b[38;5;241m=\u001b[39m language_model\u001b[38;5;241m.\u001b[39mscore(translation)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(score) \u001b[38;5;241m>\u001b[39m best_score:\n",
      "Cell \u001b[1;32mIn[4], line 76\u001b[0m, in \u001b[0;36mIBMModel1.translate\u001b[1;34m(self, swedish_sentence)\u001b[0m\n\u001b[0;32m     74\u001b[0m max_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m en_word, probs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslation_probs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msw_word\u001b[49m \u001b[38;5;129;01min\u001b[39;00m probs \u001b[38;5;129;01mand\u001b[39;00m probs[sw_word] \u001b[38;5;241m>\u001b[39m max_prob:\n\u001b[0;32m     77\u001b[0m         max_prob \u001b[38;5;241m=\u001b[39m probs[sw_word]\n\u001b[0;32m     78\u001b[0m         possible_translations \u001b[38;5;241m=\u001b[39m [en_word]\n",
      "File \u001b[1;32mc:\\Users\\alexa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:1197\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_line:\n\u001b[0;32m   1196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_suspend(thread, step_cmd, original_step_cmd\u001b[38;5;241m=\u001b[39minfo\u001b[38;5;241m.\u001b[39mpydev_original_step_cmd)\n\u001b[1;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_return:  \u001b[38;5;66;03m# return event\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m     back \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mf_back\n",
      "File \u001b[1;32mc:\\Users\\alexa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel:\n",
    "    def __init__(self, corpus):\n",
    "        self.bigram_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.unigram_counts = defaultdict(int)\n",
    "        self.total_bigrams = 0\n",
    "\n",
    "        for sentence in corpus:\n",
    "            sentence = ['NULL'] + sentence + ['NULL']\n",
    "            for i in range(len(sentence) - 1):\n",
    "                self.bigram_counts[sentence[i]][sentence[i+1]] += 1\n",
    "                self.unigram_counts[sentence[i]] += 1\n",
    "                self.total_bigrams += 1\n",
    "\n",
    "    def score(self, sentence):\n",
    "        sentence = ['NULL'] + sentence + ['NULL']\n",
    "        score = 0.0\n",
    "        for i in range(len(sentence) - 1):\n",
    "            bigram_prob = self.bigram_counts[sentence[i]][sentence[i+1]] / self.unigram_counts[sentence[i]]\n",
    "            score += np.log(bigram_prob) if bigram_prob > 0 else np.log(1e-3)\n",
    "        return score\n",
    "\n",
    "\n",
    "\n",
    "class IBMModel1:\n",
    "    def __init__(self, swedish_sentences, english_sentences, iterations=10):\n",
    "        self.swedish_sentences = swedish_sentences\n",
    "        self.english_sentences = english_sentences\n",
    "        self.iterations = iterations\n",
    "        self.translation_probs = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    def get_top_translations(self, target_word, top_n=10):\n",
    "        translations = self.translation_probs.get(target_word, {})\n",
    "        sorted_translations = sorted(translations.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_translations[:top_n]\n",
    "\n",
    "    def train(self):\n",
    "        vocab_s = set(word for sentence in self.swedish_sentences for word in sentence)\n",
    "        vocab_e = set(word for sentence in self.english_sentences for word in sentence)\n",
    "        init_prob = 1.0 / len(vocab_e)\n",
    "\n",
    "        for sw, en in zip(self.swedish_sentences, self.english_sentences):\n",
    "            for sw_word in sw:\n",
    "                for en_word in en:\n",
    "                    self.translation_probs[en_word][sw_word] = init_prob\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            count = defaultdict(float)\n",
    "            total = defaultdict(float)\n",
    "\n",
    "            for sw, en in zip(self.swedish_sentences, self.english_sentences):\n",
    "                for en_word in en:\n",
    "                    total_en = sum(self.translation_probs[en_word][sw_word] for sw_word in sw)\n",
    "                    for sw_word in sw:\n",
    "                        count[(en_word, sw_word)] += self.translation_probs[en_word][sw_word] / total_en\n",
    "                        total[sw_word] += self.translation_probs[en_word][sw_word] / total_en\n",
    "\n",
    "            for (en_word, sw_word), val in count.items():\n",
    "                self.translation_probs[en_word][sw_word] = val / total[sw_word]\n",
    "\n",
    "            # Print top translations for the English word \"european\"\n",
    "            top_translations = self.get_top_translations(\"european\", top_n=10)\n",
    "            print(f\"Iteration {i+1}:\")\n",
    "            print(\"Top 10 translations for the English word 'european':\")\n",
    "            for translation, probability in top_translations:\n",
    "                print(f\"{translation}: {probability}\")\n",
    "            print()\n",
    "\n",
    "   \n",
    "\n",
    "    def translate(self, swedish_sentence):\n",
    "        english_sentence = []\n",
    "        for sw_word in swedish_sentence:\n",
    "            possible_translations = []\n",
    "            max_prob = 0.0\n",
    "            for en_word, probs in self.translation_probs.items():\n",
    "                if sw_word in probs and probs[sw_word] > max_prob:\n",
    "                    max_prob = probs[sw_word]\n",
    "                    possible_translations = [en_word]\n",
    "                elif sw_word in probs and probs[sw_word] == max_prob:\n",
    "                    possible_translations.append(en_word)\n",
    "            # Append all possible translations for the current Swedish word\n",
    "            english_sentence.append(possible_translations)\n",
    "        return english_sentence\n",
    "\n",
    "\n",
    "def argmax_translation(ibm_model, language_model, swedish_sentence):\n",
    "    best_translation = []\n",
    "    best_score = 0\n",
    "    translation = ibm_model.translate(swedish_sentence)\n",
    "\n",
    "    score = language_model.score(translation)\n",
    "\n",
    "       \n",
    "    if abs(score) > best_score:\n",
    "        best_score = score\n",
    "        best_translation = translation\n",
    "\n",
    "    # Return the best translation\n",
    "    return best_translation, best_score\n",
    "\n",
    "with open('datasets/europarl-v7.sv-en.lc.sv', 'r', encoding='utf-8') as f:\n",
    "    swedish_lines = f.readlines()\n",
    "\n",
    "with open('datasets/europarl-v7.sv-en.lc.en', 'r', encoding='utf-8') as f:\n",
    "    english_lines = f.readlines()\n",
    "\n",
    "\n",
    "sample_size = int(len(swedish_lines) * 0.01)\n",
    "\n",
    "# Randomly sample lines from the datasets\n",
    "sampled_swedish_lines = swedish_lines[:sample_size]\n",
    "sampled_english_lines = english_lines[:sample_size]\n",
    "\n",
    "# Process the sampled data\n",
    "swedish_corpus = [word_tokenize(line.strip()) for line in sampled_swedish_lines]\n",
    "english_corpus = [word_tokenize(line.strip()) for line in sampled_english_lines]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ibm_model = IBMModel1(swedish_corpus, english_corpus)\n",
    "ibm_model.train()\n",
    "\n",
    "    \n",
    "bigram_lm = BigramLanguageModel(english_corpus)\n",
    "\n",
    "swedish_sentence = ['jag', 'ber', 'er']\n",
    "best_translation, best_score = argmax_translation(ibm_model, bigram_lm, swedish_sentence)\n",
    "\n",
    "print(\"Swedish Sentence:\", swedish_sentence)\n",
    "print(\"Best English Translation:\", best_translation)\n",
    "print(\"Translation Score (log probability):\", best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
